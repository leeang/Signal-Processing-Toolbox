\newpage
\section{Speech Signal Processing}

\subsection{Analog-to-Digital Conversion}
Voices in real life are analog signals, hence before conducting digital signal processing techniques, analog-to-digital conversions are required.\\

Given a continuous-time signal $s(t)$, we define the \textit{sampled signal} by
\begin{equation}
s[n] = s(nT_s) = s(\frac{n}{F_s})
\end{equation}
where $T_s$ is the sampling interval and $F_s$ is the sampling rate.\\

$T_s$ should be carefully chosen in order to avoid distortion caused by aliasing. Telephony since the 1950s limits the information bandwidth to 300-3400 Hz \cite{EVW-report}. However, in normal conversational speech, the frequency content is mainly between 0-8000 Hz \cite{uysal2005bandwidth}. According to Nyquist-Shannon sampling theorem, we set the folding frequency $\frac{F_s}{2}$ = 8000 Hz, i.e. $F_s$ = 16 kHz.

%--------------------------------------------
%--------------------------------------------

\subsection{Pre-emphasis}

The speech production system inherently attenuates speech signal by a negative spectral slope per decade. In addition, human hearing is more sensitive to frequency band above 1 kHz \cite{picone1993signal}. However, as is depicted in Fig. \ref{zero_fft}, frequency components below 1 kHz predominantly comprise the spectrum. Hence, it is advantageous to employ a high-pass filter to amplify the high frequency range.

\begin{figure}[H]
\centering
\includegraphics[width=6in]{ang/pre_emphasis_filter}
\caption{Pre-emphasis Filters Comparison}
\label{pre_emphasis_filter}
\end{figure}

\begin{equation}
\label{high-pass-filter}
y[n] = x[n] - \alpha x[n-1]
\end{equation}

A 1st-order FIR filter represented by (\ref{high-pass-filter}) is widely implemented, including the previous group where $\alpha = 0.95$ \cite{EVW-report}. The merits of this FIR filter include simplicity and efficiency. However, Fig. \ref{pre_emphasis_filter} (\textcolor{red_matlab}{red} dash-dot line) shows that frequencies below 500 Hz are severely suppressed even though frequencies above 3 kHz are successfully amplified. Considering the potential interference caused by high-frequency noise, attenuating low frequencies too much will result in the decline of signal-to-noise ratio (SNR).

\begin{equation}
\label{shelving-filter}
y[n] = \frac{1}{a_0} \Big( b_0 x[n] + b_1 x[n-1] + b_2 x[n-3] - a_1 y[n-1] - a_2 y[n-2] \Big)
\end{equation}

Suggested by Professor Erik \textsc{Weyer}, we try to devise a shelving filter represented by (\ref{shelving-filter}) to pre-emphasize the speech signal. By trial and error, we eventually manage to obtain a appropriate filter that amplifies high frequency without attenuating low frequencies (shown in Fig. \ref{pre_emphasis_filter} by \textcolor{blue_matlab}{blue} solid line), where

\begin{align}
\label{shleving-coef}
&\begin{cases}
a_0 = 1\\
a_1 = -1.523796\\
a_2 = 0.649345
\end{cases}
&\begin{cases}
b_0 = 1.861856\\
b_1 = -3.102851\\
b_2 = 1.366544
\end{cases}
\end{align}

Fig. \ref{zero_fft} shows the spectra of word `zero' before and after pre-emphasis filter.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{ang/zero_fft}
\caption{Word `zero' Spectral Analysis}
\label{zero_fft}
\end{figure}

%--------------------------------------------
%--------------------------------------------

\subsection{Framing \& Windowing}

Speech is time-varying signals. Due to the inertial motion of articulators (speech organs such as the tongue, lips and palate), speech can be considered statistically stationary in a short-time period (approximately 30 ms) \cite{brandstein1995practical}. The time period of 30 ms indicates 30 ms $\times$ 16000 Hz = 480. We take $N = 512$ samples per frame to achieve a power 2 for efficient Fast Fourier Transform.\\

The framing operation can be finished by multiplying the signal by a moving window. For the $j$-th frame and frame length $N$, mathematical equation is given in (\ref{eq:windowing}).

\begin{equation}
\label{eq:windowing}
s_j[n] =
\begin{cases}
w[n] s[n+jN] & N = 1, 2, \dots, N\\
0, & \text{otherwise}
\end{cases}
\end{equation}

The simplest and easiest-to-implement window is a rectangular window represented by (\ref{eq:rectagular-window}).
\begin{equation}
\label{eq:rectagular-window}
w[n] =
\begin{cases}
1, & N = 1, 2, \dots, N\\
0, & \text{otherwise}
\end{cases}
\end{equation}

However, the selection of a proper window always involves a trade-off between high \textbf{frequency resolution} and low \textbf{spectral leakage}. On the one hand, convolution with mainlobe smooths the estimate over nearby frequencies and the frequency resolution is determined by the width of the mainlobe. On the other hand, the sidelobes cause sidelobe energy to appear in the spectrum, i.e. spectral leakage. (from ELEN90058 \textit{Signal Processing} lecture slides by Erik \textsc{Weyer})

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=\textwidth]{ang/windows_time}
\caption{Windows in Time Domain}
\label{windows_time}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=\textwidth]{ang/windows_frequency}
\caption{Windows in Frequency Domain}
\label{windows_frequency}
\end{minipage}
\end{figure}

\begin{table}[H]
\begin{tabu} to \textwidth {XXXXX}
\toprule
Windows &Rectangular &Hanning &Hamming &Blackman\\
\hline
Mainlobe width &$0.125 \pi$ &$0.2353 \pi$ &$0.2985 \pi$ &$0.4 \pi$\\
\hline
Peak sidelobe &-13.2 dB &-31.5 dB &-39.8 dB &-58.6 dB\\
\bottomrule
\end{tabu}
\caption{Windows Properties for $N = 16$}
\label{table:windows}
\end{table}

In terms of the windows involved in Fig. \ref{windows_time}, Fig. \ref{windows_frequency} and Table \ref{table:windows}, \textit{rectangular} window has the best frequency resolution (narrowest mainlobe) at the expense of highest spectral leakage (biggest sidelode peak) while \textit{Blackman} window has the lowest spectral leakage (smallest sidelode peak) accompanied by worst frequency resolution (widest mainlobe). Eventually, we choose an intermediate \textit{Hamming} window given in (\ref{eq:hamming}).

\begin{equation}
\label{eq:hamming}
w[n] = \alpha - \beta \cos \bigg( \frac{2 \pi n}{N-1} \bigg) \quad n = 1, 2, \dots, N
\end{equation}
where $\alpha = 25/46 \approx 0.54$ and $\beta = 1 - \alpha \approx 0.46$.

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=\textwidth]{ang/hamming_bell_shape}
\caption{Information Loss}
\label{hamming_bell_shape}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=\textwidth]{ang/hamming_overlap}
\caption{Hamming with/without overlap}
\label{hamming_overlap}
\end{minipage}
\end{figure}

Fig. \ref{hamming_bell_shape} shows the effect of the framing operation instructed by (\ref{eq:rectagular-window}) and (\ref{eq:hamming}) for $N = 512$. The \textcolor{red}{red} dash-dot ellipse in subplot 2 demonstrates the loss of information (data points near two borders are severely attenuated) due to the bell shape of the Hamming window shown in Fig. \ref{hamming_overlap} subplot 1.\\

In order to avoid information loss, we overlap each frame by half of the frame size. We choose to overlap a half primarily because the data points most attenuated in current frame will have largest gain in the next frame (shown by the \textcolor{green_html}{green} dash-dot rectangle in Fig. \ref{hamming_overlap}). Thus, information is effectively preserved.

%--------------------------------------------
%--------------------------------------------

\subsection{Thresholds}

An important task involved in speech recognition is to distinguish the informative speech (voiced \& unvoiced) frames for further processing (MFCC) from the useless silent frames that will be discarded. The basic decision-making strategy is based on the three types of speech signals (voiced, unvoiced \& silent) explained in previous section. \textbf{Energy} and \textbf{zero-crossing count} are two major metrics to determine whether a frame is voiced, unvoiced or silent.

%--------------------------------------------

\subsubsection{Energy}

The energy of a finite-length discrete signal $s_j[n]$ ($N = 1, 2, \dots, N$) is the sum of the square of the amplitudes. We define the energy of the $j$-th frame

\begin{equation}
\label{eq:frame-energy}
E_s[j] = \sum_{i=1}^{N} |s_j[i]|^2 = \sum_{i=1}^{N} (s_j[i])^2
\end{equation}

%--------------------------------------------

\subsubsection{Zero-crossing count}

\begin{figure}[H]
\centering
\includegraphics[width=3in]{ang/zero_crossing_illustration}
\caption{Zero Crossing Illustration (from Wikipedia)}
\label{zero_crossing_illustration}
\end{figure}

As is illustrated in Fig. \ref{zero_crossing_illustration}, a zero-crossing is a point where the \textbf{sign} of a signal changes, represented by a crossing of the time axis where amplitude is zero in the graph. Zero-crossing count is the times of zero-crossing occurrence in a stipulated period. Zero-crossing count of the $j$-th frame can be mathematically represented in (\ref{eq:frame-zcc}).

\begin{align}
\label{eq:frame-zcc}
zcc_s[j] &= \sum_{i=1}^{N-1} \Lambda ( s_j[i], s_j[i+1] )\\
\Lambda ( a, b ) &=
\begin{cases}
1, &\text{if } ab < 0\\
0, &\text{otherwise}
\end{cases}
\end{align}

%--------------------------------------------

\subsubsection{Features of Different Frame Types}

We manually identify the unvoiced region and voiced region (the remains are silent region) of several different words by hearing the sound and observing the waveform.

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=\textwidth]{ang/threshold_example1}
\caption{Waveform, enery \& zcc}
\label{threshold_example1}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=\textwidth]{ang/threshold_example2}
\caption{Zoomed-in Version}
\label{threshold_example2}
\end{minipage}
\end{figure}

In the case of word \textit{zero}, Fig. \ref{threshold_example1} shows the waveform and corresponding frame energy as well as the zero-crossing count of each frame. Fig. \ref{threshold_example2} is a zoomed-in version of Fig. \ref{threshold_example1}. The \textcolor{green_html}{green} dash-dot rectangle stands for the unvoiced region while the \textcolor{red}{red} dashed rectangle indicates voiced region. We can clearly see that unvoiced frames have low energy but high zero-crossing count, voiced frames have high energy but low zero-crossing count while silent frames have not only low energy but also low zero-crossing count. The relationships are summarized in Table \ref{table:thresholds}.

\begin{table}[H]
\centering
\begin{tabu} to 0.8\textwidth {XXX}
\toprule
Type &Energy &Zero-crossing count\\
\hline
Voiced &high &low\\
\hline
Unvoiced &low &high\\
\hline
Silent &low &low\\
\bottomrule
\end{tabu}
\caption{Properties of Different Frame Types}
\label{table:thresholds}
\end{table}

%--------------------------------------------

\subsubsection{Find Thresholds}

\begin{figure}[H]
\centering
\includegraphics[width=5in]{ang/threshold1}
\caption{Methodology to Find Thresholds}
\label{threshold1}
\end{figure}

\subsubsection{Decision Rule}
\begin{figure}[H]
\centering
\includegraphics[width=5in]{ang/threshold2}
\caption{Decision Rule}
\label{threshold2}
\end{figure}

%--------------------------------------------
%--------------------------------------------

\subsection{Mel Filter Bank Processing}

\subsubsection{Power Spectrum}

%--------------------------------------------

\subsubsection{Bank Filtering}

\begin{figure}[H]
\centering
\includegraphics[width=6in]{ang/mel_filter_bank_gain}
\caption{Mel Filter Bank Gain}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=6in]{ang/mel_bank_9}
\caption{Bank Filtering Demonstration}
\end{figure}

%--------------------------------------------

\subsubsection{Log Scaling}

%--------------------------------------------

\subsubsection{Discrete Cosine Transform}
